{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", message=\"numpy.ufunc size changed\")\n",
    "from skimage import io, color, transform, feature, filters\n",
    "from my_measures import BinaryClassificationPerformance  \n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT!!! Make sure you are using BinaryClassificationPerformance v1.03\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# help(BinaryClassificationPerformance)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### file paths and names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ci_path = '/Users/meeraramesh/Desktop/School/git/ml/final_assignment_2/plane_data/cropped_images/'\n",
    "l_file = '/Users/meeraramesh/Desktop/School/git/ml/final_assignment_2/plane_data/plane_labels.csv'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Function for feature building and extraction on photographsÂ¶\n",
    "\n",
    "scikit-image documentation on methods used for feature extraction:  \n",
    "\n",
    "* http://scikit-image.org/docs/dev/api/skimage.color.html#rgb2gray  \n",
    "* http://scikit-image.org/docs/dev/api/skimage.transform.html#skimage.transform.resize  \n",
    "* http://scikit-image.org/docs/stable/api/skimage.feature.html#skimage.feature.canny"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# in downscaling the image, what do you want the new dimensions to be?\n",
    "# the original dimensions of cropped images: (60, 140), which if 8,400 pixels\n",
    "dims = (15, 35) # 25% of the original size, 525 pixels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "downscaled image shape: \n",
      "(15, 35)\n",
      "image representation (first row of pixels): \n",
      "[0.03595872 0.03672943 0.01629895 0.01279022 0.01254651 0.00897317\n",
      " 0.00523036 0.00277105 0.0025309  0.00349334 0.00502946 0.00652903\n",
      " 0.0062032  0.00346726 0.00199169 0.00260336 0.00416323 0.00709959\n",
      " 0.00751603 0.00737113 0.01142706 0.01309353 0.00919321 0.00459549\n",
      " 0.00226189 0.00313457 0.00847177 0.01947856 0.04009014 0.06964681\n",
      " 0.06974397 0.04294428 0.03509388 0.04756239 0.04235021]\n",
      "\n",
      "\n",
      "example of transformation: \n"
     ]
    }
   ],
   "source": [
    "def image_manipulation(imname, imgs_path, imview=False):\n",
    "    warnings.filterwarnings('ignore')\n",
    "    imname = imgs_path + imname + '.png'\n",
    "    img_raw = io.imread(imname, as_gray=True)\n",
    "    downscaled = transform.resize(img_raw, (dims[0], dims[1])) # downscale image\n",
    "    final_image = filters.hessian(downscaled) # hessian filter that \"can be used to detect continuous edges\"\n",
    "    final_image = feature.canny(final_image) # edge filter image with Canny algorithm\n",
    "    final_image = feature.corner_harris(downscaled, 2, 4, 0.04) # reduce to just corner features, change from 3 to 4 \n",
    "    \n",
    "    if imview==True:\n",
    "        plt.figure()\n",
    "        plt.imshow(final_image, cmap='Greys')\n",
    "        plt.show()\n",
    "    warnings.filterwarnings('always')\n",
    "    return final_image\n",
    "\n",
    "# test the function, look at input/output\n",
    "# me: changed to matplotlib bc io.imshow doesn't work\n",
    "test_image = image_manipulation('2017-08-25T23+24+13_390Z', ci_path, True)\n",
    "print('downscaled image shape: ')\n",
    "print(test_image.shape)\n",
    "print('image representation (first row of pixels): ')\n",
    "print(test_image[0])\n",
    "print('\\n')\n",
    "print('example of transformation: ')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "for comparison, look at original image:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# function to process raw images, resulting in training and test datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# function that takes raw images and completes all preprocessing required before model fits\n",
    "def process_raw_data(labels_fn, images_fp, my_random_seed, imview=False, test=False):\n",
    "    plane_data = pd.read_csv(labels_fn) # read in photograph labels\n",
    "    print(\"First few lines of image labels: \")\n",
    "    print(plane_data.head())\n",
    "    print(\"Size of image label dataFrame: \")\n",
    "    print(plane_data.shape)\n",
    "        \n",
    "    # construct lists for features, labels, and a crosswalk reference to image names\n",
    "    features_list = []\n",
    "    if (not test):\n",
    "        y_list = []\n",
    "    imnames_list = []\n",
    "\n",
    "    for index, row in plane_data.iterrows():\n",
    "        new_img = image_manipulation(row['img_name'], images_fp)\n",
    "        features_list.append(new_img)\n",
    "        if (not test):\n",
    "            y_list.append(row['plane'])\n",
    "        imnames_list.append(row['img_name']) \n",
    "   \n",
    "    # convert the lists to ndarrays\n",
    "    features = np.asarray(features_list)\n",
    "    if (not test):\n",
    "        Y = np.asarray(y_list)\n",
    "    imgs = np.asarray(imnames_list)\n",
    "    print('Shape of original feature representation: ')\n",
    "    print(features.shape)\n",
    "\n",
    "    # flatten the images ndarray to one row per image\n",
    "    features_flat = features.reshape((features.shape[0], -1))\n",
    "\n",
    "    print('Shape of flat feature representation: ')\n",
    "    print(features_flat.shape)\n",
    "\n",
    "    if (not test):\n",
    "        print('Shape of Y: ')\n",
    "        print(Y.shape)\n",
    "\n",
    "        print('Number of images with planes: ')\n",
    "        print(Y.sum())\n",
    "    \n",
    "        # create train and test sets\n",
    "        data_train, data_test, y_train, y_test, imgs_train, imgs_test = train_test_split(features_flat, \n",
    "            Y, imgs, test_size = 0.25, random_state = my_random_seed)\n",
    "\n",
    "        print('Shape of training set: ')\n",
    "        print(y_train.shape)\n",
    "        print('Number of training images that contain an airplane: ')\n",
    "        print(y_train.sum())\n",
    "\n",
    "        print('Shape of test set: ')\n",
    "        print(y_test.shape)\n",
    "        print('Number of test images that contain an airplane: ')\n",
    "        print(y_test.sum())\n",
    "    \n",
    "    if (test):\n",
    "        X_submission_test = features_flat\n",
    "        print(\"Shape of X_test for submission:\")\n",
    "        print(X_submission_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(X_submission_test, plane_data)\n",
    "    else: \n",
    "        print(\"Shape of data_train and data_test:\")\n",
    "        print(data_train.shape)\n",
    "        print(data_test.shape)\n",
    "        print(\"Shape of y_train and y_test:\")\n",
    "        print(y_train.shape)\n",
    "        print(y_test.shape)\n",
    "        print(\"Shape of imgs_train and imgs_test:\")\n",
    "        print(imgs_train.shape)\n",
    "        print(imgs_test.shape)\n",
    "        print('SUCCESS!')\n",
    "        return(data_train, data_test, y_train, y_test, imgs_train, imgs_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few lines of image labels: \n",
      "                   img_name  plane\n",
      "0  2016-08-02T13+50+24_430Z  False\n",
      "1  2016-08-02T14+12+37_390Z  False\n",
      "2  2016-08-02T22+20+26_600Z  False\n",
      "3  2016-08-03T12+04+30_670Z  False\n",
      "4  2016-08-03T12+32+21_790Z  False\n",
      "Size of image label dataFrame: \n",
      "(6758, 2)\n",
      "Shape of original feature representation: \n",
      "(6758, 15, 35)\n",
      "Shape of flat feature representation: \n",
      "(6758, 525)\n",
      "Shape of Y: \n",
      "(6758,)\n",
      "Number of images with planes: \n",
      "101\n",
      "Shape of training set: \n",
      "(5068,)\n",
      "Number of training images that contain an airplane: \n",
      "80\n",
      "Shape of test set: \n",
      "(1690,)\n",
      "Number of test images that contain an airplane: \n",
      "21\n",
      "Shape of data_train and data_test:\n",
      "(5068, 525)\n",
      "(1690, 525)\n",
      "Shape of y_train and y_test:\n",
      "(5068,)\n",
      "(1690,)\n",
      "Shape of imgs_train and imgs_test:\n",
      "(5068,)\n",
      "(1690,)\n",
      "SUCCESS!\n"
     ]
    }
   ],
   "source": [
    "data_train, data_test, y_train, y_test, imgs_train, imgs_test = process_raw_data(l_file, ci_path, \n",
    "    my_random_seed=13, imview=False, test=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# train Multilayer Perceptron, a.k.a. neural network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLPClassifier(alpha=0.0003,\n",
      "              hidden_layer_sizes=(100, 100, 100, 100, 100, 100, 100, 100, 100,\n",
      "                                  100, 100, 100, 50),\n",
      "              max_iter=10000000000000)\n",
      "TRAINING SET 8: \n",
      "{'Pos': 80, 'Neg': 4988, 'TP': 80, 'TN': 4988, 'FP': 0, 'FN': 0, 'Accuracy': 1.0, 'Precision': 1.0, 'Recall': 1.0, 'desc': 'nn8', 'set': 'train'}\n",
      "TEST SET 8: \n",
      "{'Pos': 21, 'Neg': 1669, 'TP': 18, 'TN': 1667, 'FP': 2, 'FN': 3, 'Accuracy': 0.9970414201183432, 'Precision': 0.9, 'Recall': 0.8571428571428571, 'desc': 'nn8', 'set': 'test'}\n"
     ]
    }
   ],
   "source": [
    "from sklearn import neural_network\n",
    "nn8 = neural_network.MLPClassifier(hidden_layer_sizes = (100,100,100,100,100,100,100,100,100,100,100,100,50), alpha = .0003, max_iter=10000000000000)\n",
    "print(nn8)\n",
    "nn8.fit(data_train, y_train)\n",
    "\n",
    "nn8_performance = BinaryClassificationPerformance(nn8.predict(data_train), y_train, 'nn8')\n",
    "nn8_performance.compute_measures()\n",
    "nn8_performance.performance_measures['set'] = 'train'\n",
    "print('TRAINING SET 8: ')\n",
    "print(nn8_performance.performance_measures)\n",
    "\n",
    "nn8_performance_test = BinaryClassificationPerformance(nn8.predict(data_test), y_test, 'nn8')\n",
    "nn8_performance_test.compute_measures()\n",
    "nn8_performance_test.performance_measures['set'] = 'test'\n",
    "print('TEST SET 8: ')\n",
    "print(nn8_performance_test.performance_measures)\n",
    "\n",
    "nn8_performance_test.img_indices()\n",
    "nn8_img_indices_to_view = nn8_performance_test.image_indices"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# look at examples of neural network classifications"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## true positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance_examples('TP', nn_img_indices_to_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## false positives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance_examples('FP', nn_img_indices_to_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## false negatives"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# performance_examples('FN', nn_img_indices_to_view)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SUBMISSION\n",
    "\n",
    "### file paths and names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission_ci_path = '/Users/meeraramesh/Desktop/School/git/ml/final_assignment_2/test_data_for_grading/test_cropped_images/' # file path for cropped images for training\n",
    "submission_l_file = '/Users/meeraramesh/Desktop/School/git/ml/final_assignment_2/test_data_for_grading/test_plane_labels.csv' # file path and file name for csv with labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "First few lines of image labels: \n",
      "                   img_name\n",
      "0  2016-08-02T13+50+24_430Z\n",
      "1  2016-08-02T14+12+37_390Z\n",
      "2  2016-08-03T12+32+21_790Z\n",
      "3  2016-08-03T13+19+28_320Z\n",
      "4  2016-08-05T15+24+58_670Z\n",
      "Size of image label dataFrame: \n",
      "(1523, 1)\n",
      "Shape of original feature representation: \n",
      "(1523, 15, 35)\n",
      "Shape of flat feature representation: \n",
      "(1523, 525)\n",
      "Shape of X_test for submission:\n",
      "(1523, 525)\n",
      "SUCCESS!\n",
      "Number of rows in the submission test set (should be 1,523): \n"
     ]
    }
   ],
   "source": [
    "X_test_data, X_test_submission = process_raw_data(submission_l_file, submission_ci_path, my_random_seed=13, test=True)\n",
    "print(\"Number of rows in the submission test set (should be 1,523): \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORTANT CHECK: make sure that the number of columns in your training data is the same as the number of columns in this test submission!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(5068, 525)\n",
      "(1523, 525)\n"
     ]
    }
   ],
   "source": [
    "print(data_train.shape)\n",
    "print(X_test_data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both the training set and submission test set have 525 columns. Success!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "Choose a *single* model for your submission. In this code, I am choosing the Perceptron model fit, which is in the prc object. But you should choose the model that is performing the best for you!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.014445173998686802\n"
     ]
    }
   ],
   "source": [
    "# concatenate predictions to the id\n",
    "X_test_submission[\"prediction\"] = nn8.predict(X_test_data) #neural net w/ hidden_layer_sizes=(100, 100, 100, 100, 100, 100, 100, 100, 100, 100)\n",
    "# look at the proportion of positive predictions\n",
    "print(X_test_submission['prediction'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the proportion of predictions that have predicted that there is an airplane in the image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1523, 2)\n"
     ]
    }
   ],
   "source": [
    "print(X_test_submission.shape) # should be (1523, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export submission file as pdf\n",
    "# CHANGE FILE PATH: \n",
    "X_test_submission.to_csv('/Users/meeraramesh/Desktop/airplane_submission2.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "submission 1 performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'Pos': 23,\n",
       "  'Neg': 1500,\n",
       "  'TP': 18,\n",
       "  'TN': 1495,\n",
       "  'FP': 5,\n",
       "  'FN': 5,\n",
       "  'pos': 0.015101772816808929,\n",
       "  'neg': 0.9848982271831911,\n",
       "  'clr': 0.015333333333333332,\n",
       "  'acc': 0.9934340118187788,\n",
       "  'err': 0.006565988181221227,\n",
       "  'tpr': 0.782608695652174,\n",
       "  'tnr': 0.9966666666666667,\n",
       "  'fpr': 0.0033333333333333335,\n",
       "  'fnr': 0.21739130434782608,\n",
       "  'prec': 0.782608695652174,\n",
       "  'name': '1_meera'},)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "{'Pos': 23, 'Neg': 1500, 'TP': 18, 'TN': 1495, 'FP': 5, 'FN': 5, 'pos': 0.015101772816808929, 'neg': 0.9848982271831911, 'clr': 0.015333333333333332, 'acc': 0.9934340118187788, 'err': 0.006565988181221227, 'tpr': 0.782608695652174, 'tnr': 0.9966666666666667, 'fpr': 0.0033333333333333335, 'fnr': 0.21739130434782608, 'prec': 0.782608695652174, 'name': '1_meera'}, "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
